import asyncio
import logging
from datetime import datetime
from typing import List, Dict, Optional
from bot.utils.rss_parser import parse_multiple_feeds
from bot.utils.together_api import together_api
from bot.utils.news_cache import news_cache
from bot.data.rss_feeds import RSS_FEEDS

logger = logging.getLogger(__name__)

class NewsProcessor:
    def __init__(self):
        self.processing_lock = asyncio.Lock()
        
    async def process_category_news(self, category: str, force_update: bool = False) -> bool:
        """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –Ω–æ–≤–æ—Å—Ç–∏ –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–π –∫–∞—Ç–µ–≥–æ—Ä–∏–∏"""
        async with self.processing_lock:
            try:
                logger.info(f"üîÑ –ù–∞—á–∏–Ω–∞–µ–º –æ–±—Ä–∞–±–æ—Ç–∫—É –∫–∞—Ç–µ–≥–æ—Ä–∏–∏: {category}")
                
                if category not in RSS_FEEDS:
                    logger.error(f"‚ùå –ö–∞—Ç–µ–≥–æ—Ä–∏—è {category} –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ –≤ RSS_FEEDS")
                    return False
                
                # –ü–æ–ª—É—á–∞–µ–º RSS –ª–µ–Ω—Ç—ã –¥–ª—è –∫–∞—Ç–µ–≥–æ—Ä–∏–∏
                feeds = RSS_FEEDS[category]
                feed_urls = list(feeds.values())
                
                logger.info(f"üì° –ü–∞—Ä—Å–∏–Ω–≥ {len(feed_urls)} RSS –ª–µ–Ω—Ç –¥–ª—è –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ {category}")
                
                # –ü–∞—Ä—Å–∏–º –≤—Å–µ RSS –ª–µ–Ω—Ç—ã –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ
                all_news = await parse_multiple_feeds(feed_urls, max_items_per_feed=5)
                
                if not all_news:
                    logger.warning(f"‚ö†Ô∏è –ù–µ –ø–æ–ª—É—á–µ–Ω–æ –Ω–æ–≤–æ—Å—Ç–µ–π –¥–ª—è –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ {category}")
                    return False
                
                logger.info(f"üì∞ –ü–æ–ª—É—á–µ–Ω–æ {len(all_news)} –Ω–æ–≤–æ—Å—Ç–µ–π –¥–ª—è –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ {category}")
                
                # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –Ω–æ–≤–æ—Å—Ç–∏ —á–µ—Ä–µ–∑ AI
                processed_news = await self._process_news_with_ai(all_news, category)
                
                if processed_news:
                    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –∫–µ—à
                    success = await news_cache.save_news(category, processed_news)
                    if success:
                        logger.info(f"‚úÖ –ö–∞—Ç–µ–≥–æ—Ä–∏—è {category} —É—Å–ø–µ—à–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–∞ –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞")
                        return True
                    else:
                        logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –Ω–æ–≤–æ—Å—Ç–µ–π –¥–ª—è –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ {category}")
                        return False
                else:
                    logger.error(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å –Ω–æ–≤–æ—Å—Ç–∏ –¥–ª—è –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ {category}")
                    return False
                    
            except Exception as e:
                logger.error(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ {category}: {e}")
                return False
    
    async def _process_news_with_ai(self, news_list: List[Dict], category: str) -> List[Dict]:
        """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –Ω–æ–≤–æ—Å—Ç–∏ —á–µ—Ä–µ–∑ AI –∫–∞–∫ —Ä–µ–¥–∞–∫—Ç–æ—Ä"""
        try:
            logger.info(f"ü§ñ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º {len(news_list)} –Ω–æ–≤–æ—Å—Ç–µ–π –¥–ª—è –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ {category}")
            
            # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –Ω–æ–≤–æ—Å—Ç–∏ –±–∞—Ç—á–∞–º–∏
            batch_size = 3  # –£–º–µ–Ω—å—à–∞–µ–º —Ä–∞–∑–º–µ—Ä –±–∞—Ç—á–∞ –¥–ª—è —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏
            processed_news = []
            
            for i in range(0, len(news_list), batch_size):
                batch = news_list[i:i + batch_size]
                
                logger.info(f"üîÑ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –±–∞—Ç—á {i//batch_size + 1} –∏–∑ {(len(news_list) + batch_size - 1)//batch_size}")
                
                # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –±–∞—Ç—á —á–µ—Ä–µ–∑ AI
                batch_results = await together_api.process_news_batch(batch)
                
                if batch_results:
                    processed_news.extend(batch_results)
                    logger.info(f"‚úÖ –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ {len(batch_results)} –Ω–æ–≤–æ—Å—Ç–µ–π –≤ –±–∞—Ç—á–µ")
                else:
                    logger.warning(f"‚ö†Ô∏è –ë–∞—Ç—á –Ω–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω, –¥–æ–±–∞–≤–ª—è–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—ã")
                    # –î–æ–±–∞–≤–ª—è–µ–º –Ω–µ–æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ –Ω–æ–≤–æ—Å—Ç–∏
                    for news_item in batch:
                        processed_news.append({
                            **news_item,
                            'content': news_item.get('summary', ''),
                            'ai_processed': False
                        })
                
                # –ü–∞—É–∑–∞ –º–µ–∂–¥—É –±–∞—Ç—á–∞–º–∏
                await asyncio.sleep(2)
            
            logger.info(f"‚úÖ –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ {len(processed_news)} –∏–∑ {len(news_list)} –Ω–æ–≤–æ—Å—Ç–µ–π –¥–ª—è –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ {category}")
            return processed_news
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ AI –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–ª—è –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ {category}: {e}")
            # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –Ω–µ–æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ –Ω–æ–≤–æ—Å—Ç–∏
            return [{
                **news_item,
                'content': news_item.get('summary', ''),
                'ai_processed': False,
                'error': str(e)
            } for news_item in news_list]
    
    async def process_all_categories(self) -> Dict[str, bool]:
        """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –≤—Å–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ –Ω–æ–≤–æ—Å—Ç–µ–π"""
        results = {}
        
        logger.info("üöÄ –ù–∞—á–∏–Ω–∞–µ–º –ø–æ–ª–Ω—É—é –æ–±—Ä–∞–±–æ—Ç–∫—É –≤—Å–µ—Ö –∫–∞—Ç–µ–≥–æ—Ä–∏–π –Ω–æ–≤–æ—Å—Ç–µ–π")
        
        for category in RSS_FEEDS.keys():
            try:
                logger.info(f"üîÑ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∫–∞—Ç–µ–≥–æ—Ä–∏—é: {category}")
                success = await self.process_category_news(category)
                results[category] = success
                
                if success:
                    logger.info(f"‚úÖ –ö–∞—Ç–µ–≥–æ—Ä–∏—è {category} —É—Å–ø–µ—à–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–∞")
                else:
                    logger.error(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ {category}")
                
                # –ü–∞—É–∑–∞ –º–µ–∂–¥—É –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º–∏
                await asyncio.sleep(3)
                
            except Exception as e:
                logger.error(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ {category}: {e}")
                results[category] = False
        
        successful = sum(1 for success in results.values() if success)
        total = len(results)
        
        logger.info(f"üèÅ –ü–æ–ª–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞: {successful}/{total} –∫–∞—Ç–µ–≥–æ—Ä–∏–π —É—Å–ø–µ—à–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ")
        
        return results

# –°–æ–∑–¥–∞–µ–º –≥–ª–æ–±–∞–ª—å–Ω—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä–∞
news_processor = NewsProcessor()
